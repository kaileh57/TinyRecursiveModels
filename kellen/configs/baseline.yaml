# Baseline TRM Configuration for Sudoku-Extreme
# Target: Replicate paper's ~87% accuracy result

defaults:
  - arch_config: trm_baseline
  - _self_

# TPU Configuration
use_tpu: true
num_workers: 8

# Data paths
data_paths: ['data/sudoku-extreme-1k-aug-1000']
data_paths_test: []

# Evaluators
evaluators: []

# Hyperparameters - Training
global_batch_size: 6144  # 768 per worker Ã— 8 workers
epochs: 50000
eval_interval: 5000
min_eval_interval: 0
checkpoint_every_eval: true
save_checkpoint_steps: 1000

# Learning rate
lr: 1.0e-4
lr_min_ratio: 1.0  # Constant LR (no decay)
lr_warmup_steps: 2000

# Optimizer
beta1: 0.9
beta2: 0.95
weight_decay: 1.0

# Puzzle embeddings
puzzle_emb_lr: 1.0e-4
puzzle_emb_weight_decay: 1.0

# Regularization
ema: true
ema_rate: 0.999
freeze_weights: false

# Reproducibility
seed: 0

# Logging
project_name: "TRM-Scaling-Research"
run_name: null  # Auto-generated
checkpoint_path: "gs://sculptor-tpu-experiments/checkpoints"  # GCS bucket for TPU v4-64
load_checkpoint: null

# Evaluation
eval_save_outputs: []
